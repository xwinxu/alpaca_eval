Contextual-KTO-Mistral-PairRM: # this should be the same as the name as the current directory
  prompt_template: "Contextual-KTO-Mistral-PairRM/prompt.txt"
  fn_completions: "vllm_local_completions"
  completions_kwargs:
    # model_name: "ContextualAI/Contextual_KTO_Mistral_PairRM"
    # model_name: /data/models/yi34_kto_pairrm/kto_mistral7b_instruct_v2_snorkel_pairrm_iter1_b0.1/LATEST
    # model_name: /data/models/yi34_kto_pairrm/kto_mistral7b_instruct_v2_snorkel_pairrm_iter2_b0.1/LATEST
    model_name: /data/models/yi34_kto_pairrm/kto_mistral7b_instruct_v2_snorkel_pairrm_iter3_b0.1/LATEST
    model_kwargs:
      torch_dtype: 'bfloat16'
      tokenizer_mode: "auto"
      trust_remote_code: True
    max_new_tokens: 2048
    temperature: 0.7
    top_p: 0.95
    batch_size: 900
  # pretty_name: "Contextual AI (KTO-Mistral-PairRM)" # name in the leaderboard
  # pretty_name: "Contextual AI (KTO-Mistral-PairRM) Iter 1 (temp 0.7)"
  # pretty_name: "Contextual AI (KTO-Mistral-PairRM) Iter 2 (temp 0.7)"
  pretty_name: "Contextual AI (KTO-Mistral-PairRM) Iter 3 (temp 0.7)"
  # link: "https://huggingface.co/ContextualAI/Contextual_KTO_Mistral_PairRM" # link to the model's repo/information in the leaderboard
