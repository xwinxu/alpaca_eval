Contextual-Mixtral-KTO-PairRM-iter2-rejsamp: # this should be the same as the name as the current directory
  prompt_template: "Contextual-Mixtral-KTO-PairRM-iter2-rejsamp/prompt.txt"
  fn_completions: "vllm_local_completions"
  completions_kwargs:
    model_name: "/home/winnie/halos/trl/train_kto_mixtral_iter2/32gpusds_kto_32gpusds_kto_Mixtral-8x7B-Instruct-v0.1_iter1_rej_sample"
    model_kwargs:
      torch_dtype: 'bfloat16'
      tokenizer_mode: "auto"
      trust_remote_code: True
      tp: 2
    max_new_tokens: 2048
    # gpu_memory_utilization: 0.95
    temperature: 0.7
    top_p: 0.95
    batch_size: 900
  pretty_name: "Contextual AI (KTO-Mixtral-PairRM) temp07" # name in the leaderboard
  # link: "https://huggingface.co/ContextualAI/Contextual_KTO_Mistral_PairRM hf" # link to the model's repo/information in the leaderboard


# Contextual-Mixtral-KTO-PairRM-iter3: # this should be the same as the name as the current directory
#   prompt_template: "Contextual-Mixtral-KTO-PairRM-iter3/prompt.txt"
#   fn_completions: "openai_completions"
#   completions_kwargs:
#     model_name: "/home/winnie/halos/trl/train_kto_mixtral_iter3/32gpusds_kto_32gpusds_kto_32gpusds_kto_Mixtral-8x7B-Instruct-v0.1" # "ContextualAI/Contextual-Mixtral-KTO-PairRM-iter3"
#     max_tokens: 4096
#     requires_chatml: True
#     num_procs: 8
#     client_kwargs:
#       base_url: 'https://api.together.xyz'
#   pretty_name: "Mixtral 8x7B v0.1"
#   link: "https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1"